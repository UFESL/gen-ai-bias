{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8662fd9-5b33-4dcc-ad49-8e26487d6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/blue/prabhat/parvath.harikris/gen-ai-bias/boosting'\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "import fid_custom\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.models as models\n",
    "from torchvision.models import Inception_V3_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77736136-2dc1-43cd-a647-31648f525a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "celebA_data = f'{root}/celebA_data/celebA_fid_stats.npz'\n",
    "biased_data = f'{root}/biased_datasets/Smiling_Young_Male_99_Not_Male_1_N15000'\n",
    "out = f'{root}/GANs/gan_chain_fid/outputs/gan_iter'\n",
    "\n",
    "real_stats = fid_custom.load_stats(celebA_data)\n",
    "biased_stats = fid_custom.features_to_stat(f'{biased_data}/features', f'{out}_1/features')\n",
    "\n",
    "fid_custom.calculate_fid(*list(real_stats.values())[:2],*list(biased_stats.values())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e173380-a7d3-43b9-8d2b-62f4518feccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 50\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "# Dataset and Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset0 = datasets.ImageFolder(\"/blue/prabhat/parvath.harikris/gen-ai-bias/boosting/biased_datasets/Smiling_Young_Male_99_Not_Male_1_N15000/images\", transform=transform)\n",
    "dataset1 = datasets.ImageFolder(\"/blue/prabhat/parvath.harikris/gen-ai-bias/boosting/GANs/gan_chain_fid/outputs/gan_iter_1/images\", transform=transform)\n",
    "\n",
    "dataset = ConcatDataset([dataset0, dataset1])\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=torch.get_num_threads(), pin_memory=True)\n",
    "\n",
    "# Visualize a batch of training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceef215-d632-4498-848e-197f69cf8795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu_r, sigma_r, Nr = list(real_stats.values())\n",
    "mu_g, sigma_g, Ng = list(biased_stats.values())\n",
    "\n",
    "mu_r = torch.tensor(mu_r).to(device)\n",
    "sigma_r = torch.tensor(sigma_r).to(device)\n",
    "\n",
    "mu_g = torch.tensor(mu_g).to(device)\n",
    "sigma_g = torch.tensor(sigma_g).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92204400-099a-4e03-89bf-d62bee7f9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dataset0) == 15000\n",
    "assert len(dataset1) == 100\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163ca6a-5fd7-4e88-b967-17d80547de63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For FID loss\n",
    "inception = models.inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "inception.fc = torch.nn.Identity()  # Remove classification head\n",
    "inception.eval().to(device).requires_grad_(False);  # Disable gradients globally\n",
    "resize = transforms.Resize((299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d80cd-b39b-4a67-8dd5-e901afd95d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fid_loss_batch(fake, alpha = 0.25):    ## Approximate fid\n",
    "    f = inception(resize(fake))\n",
    "    diff = f - mu_g\n",
    "    mu = mu_g + diff/(Ng + 1)\n",
    "    sigma = ((Ng - 1) * sigma_g) / Ng + torch.einsum('bi,bj->bij', diff, diff) / (Ng + 1)\n",
    "    \n",
    "    mean_diff = torch.sum((mu - mu_r) ** 2)\n",
    "    cov_diff = torch.sum((sigma - sigma_r) ** 2)\n",
    "    \n",
    "    fid_score = (mean_diff + alpha * cov_diff)/BATCH_SIZE\n",
    "    \n",
    "    return fid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c4944-0cd1-4418-84fb-5435606ca998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_sigma_update_batch_torch(mu_a, sigma_a, Na, mu_b, sigma_b, Nb):\n",
    "    mu_new = (Na*mu_a + Nb*mu_b)/ (Na + Nb)\n",
    "    sigma_new = ((Na-1)*sigma_a + (Nb-1)*sigma_b + Na*Nb*torch.ger(mu_a-mu_b, mu_a-mu_b)/(Na+Nb))/(Na+Nb-1)\n",
    "    return mu_new, sigma_new, Na+Nb\n",
    "\n",
    "def calculate_fid_torch(mu1, sigma1, mu2, sigma2):\n",
    "    diff = mu1 - mu2\n",
    "    mean_term = torch.sum(diff ** 2)\n",
    "    covmean = _sqrtm_newton_schulz(sigma1 @ sigma2)\n",
    "    cov_diff = torch.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return mean_term + cov_diff\n",
    "\n",
    "def _sqrtm_newton_schulz(matrix, num_iters=50):\n",
    "    dim = matrix.shape[0]\n",
    "    norm = torch.norm(matrix)\n",
    "    Y = matrix / norm\n",
    "    I = torch.eye(dim, device=matrix.device, dtype=matrix.dtype)\n",
    "    Z = torch.eye(dim, device=matrix.device, dtype=matrix.dtype)\n",
    "    for _ in range(num_iters):\n",
    "        T = 0.5 * (3.0 * I - Z @ Y)\n",
    "        Y = Y @ T\n",
    "        Z = T @ Z\n",
    "    return Y * torch.sqrt(norm)\n",
    "\n",
    "def fid_loss_batch_exact(fake):     ## Exact Fid\n",
    "    f = inception(resize(fake))\n",
    "    mu_b = f.mean(dim=0)\n",
    "    sigma_b = torch.cov(f.T)\n",
    "    \n",
    "    mu, sigma, N = mu_sigma_update_batch_torch(mu_g, sigma_g, Ng, mu_b, sigma_b, BATCH_SIZE)\n",
    "    \n",
    "    return calculate_fid_torch(mu_r, sigma_r, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb3ebe-5d11-417b-8937-776907cceb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(z_dim, features_g * 16, 4, 1, 0),\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Weight Initialization\n",
    "def initialize_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)\n",
    "\n",
    "# Initialize models\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "# Optimizers and Loss Function\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Fixed Noise for Visualization\n",
    "fixed_noise = torch.randn(64, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "LAMBDA_fid = 1\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "    for batch_idx, (real, _) in loop:\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        # Labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1, 1, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, 1, 1).to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        opt_disc.zero_grad()\n",
    "        \n",
    "        # Real images\n",
    "        real_pred = disc(real)\n",
    "        real_loss = criterion(real_pred, real_labels)\n",
    "        \n",
    "        # Fake images\n",
    "        noise = torch.randn(batch_size, Z_DIM, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        fake_pred = disc(fake.detach())  \n",
    "        fake_loss = criterion(fake_pred, fake_labels)\n",
    "        \n",
    "        disc_loss = real_loss + fake_loss\n",
    "        disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        opt_gen.zero_grad()\n",
    "        \n",
    "        fake_pred = disc(fake)\n",
    "        adv_loss = criterion(fake_pred, real_labels)  # Adversarial loss\n",
    "        fid_loss = fid_loss_batch_exact(fake)  # FID loss\n",
    "        \n",
    "        gen_loss = adv_loss + LAMBDA_fid * fid_loss  # Weighted sum\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        loop.set_postfix({\n",
    "            \"D_loss\": f\"{disc_loss.item():.4f}\",\n",
    "            \"G_loss\": f\"{gen_loss.item():.4f}\",\n",
    "            \"FID_loss\": f\"{fid_loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    # Generate Images for Visualization\n",
    "    with torch.no_grad():\n",
    "        fake_images = gen(fixed_noise).detach().cpu()\n",
    "        img_grid = make_grid(fake_images, nrow=8, normalize=True)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6bdb95-6a02-4be8-a289-234ecc1c0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random noise vector\n",
    "random_noise = torch.randn(1, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "# Generate a random image\n",
    "with torch.no_grad():\n",
    "    random_image = gen(random_noise).detach().cpu()\n",
    "\n",
    "# Convert the tensor to a grid and display the image\n",
    "img_grid = make_grid(random_image, nrow=1, normalize=True)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27198c-255e-4cdf-8f75-272f90693a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_ = 2\n",
    "n = 100\n",
    "save_dir = f\"outputs/gan_iter_{iter_}/images/class\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "gen.eval()  # Set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for i in range(n):\n",
    "        noise = torch.randn(1, Z_DIM, 1, 1).to(device)  # Generate random noise\n",
    "        fake_image = gen(noise)  # Generate image\n",
    "        save_image(fake_image, os.path.join(save_dir, f\"generated_{i+1}.png\"), normalize=True)\n",
    "\n",
    "fid_custom.extract_and_save_features(save_dir, f\"outputs/gan_iter_{iter_}/features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
