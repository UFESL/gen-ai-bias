{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8662fd9-5b33-4dcc-ad49-8e26487d6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/blue/prabhat/parvath.harikris/gen-ai-bias/boosting')\n",
    "\n",
    "import fid_custom\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.models as models\n",
    "from torchvision.models import Inception_V3_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e173380-a7d3-43b9-8d2b-62f4518feccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 50\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "# Dataset and Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset0 = datasets.ImageFolder(\"/blue/prabhat/parvath.harikris/gen-ai-bias/boosting/biased_datasets/Smiling_Young_Male_99_Not_Male_1_N15000/images\", transform=transform)\n",
    "dataset1 = datasets.ImageFolder(\"/blue/prabhat/parvath.harikris/gen-ai-bias/boosting/GANs/gan_chain/outputs/gan_iter_1/images\", transform=transform)\n",
    "dataset2 = datasets.ImageFolder(\"/blue/prabhat/parvath.harikris/gen-ai-bias/boosting/GANs/gan_chain/outputs/gan_iter_2/images\", transform=transform)\n",
    "dataset3 = datasets.ImageFolder(\"/blue/prabhat/parvath.harikris/gen-ai-bias/boosting/GANs/gan_chain/outputs/gan_iter_3/images\", transform=transform)\n",
    "\n",
    "dataset = ConcatDataset([dataset0, dataset1, dataset2, dataset3])\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=torch.get_num_threads(), pin_memory=True)\n",
    "\n",
    "# Visualize a batch of training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92204400-099a-4e03-89bf-d62bee7f9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dataset0) == 15000\n",
    "assert len(dataset1) == 100\n",
    "assert len(dataset2) == 100\n",
    "assert len(dataset3) == 100\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163ca6a-5fd7-4e88-b967-17d80547de63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pre-trained Inception v3 model\n",
    "inception_ld = models.inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "inception_ld.eval().to(device).requires_grad_(False)  # Disable gradients globally\n",
    "\n",
    "# Hook to extract features from Mixed_6e\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(*list(model.children())[:14])  # Up to Mixed_6e\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "# Create the feature extractor\n",
    "inception_mixed6e = FeatureExtractor(inception_ld).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb3ebe-5d11-417b-8937-776907cceb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(z_dim, features_g * 16, 4, 1, 0),\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Weight Initialization\n",
    "def initialize_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)\n",
    "\n",
    "# Initialize models\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "# Optimizers and Loss Function\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Fixed Noise for Visualization\n",
    "fixed_noise = torch.randn(64, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "v3_resize = transforms.Resize((299,299))\n",
    "\n",
    "# Define perceptual loss function\n",
    "def perceptual_loss(fake, real):\n",
    "    real_features = inception_mixed6e(v3_resize(real))\n",
    "    fake_features = inception_mixed6e(v3_resize(fake))\n",
    "    return torch.nn.functional.mse_loss(fake_features, real_features)\n",
    "\n",
    "LAMBDA_PERC = 0.1\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "    for batch_idx, (real, _) in loop:\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        # Labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1, 1, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, 1, 1).to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        opt_disc.zero_grad()\n",
    "        \n",
    "        # Real images\n",
    "        real_pred = disc(real)\n",
    "        real_loss = criterion(real_pred, real_labels)\n",
    "        \n",
    "        # Fake images\n",
    "        noise = torch.randn(batch_size, Z_DIM, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        fake_pred = disc(fake.detach())  \n",
    "        fake_loss = criterion(fake_pred, fake_labels)\n",
    "        \n",
    "        disc_loss = real_loss + fake_loss\n",
    "        disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        opt_gen.zero_grad()\n",
    "        \n",
    "        fake_pred = disc(fake)\n",
    "        adv_loss = criterion(fake_pred, real_labels)  # Adversarial loss\n",
    "        perc_loss = perceptual_loss(fake, real)  # Perceptual loss\n",
    "        \n",
    "        gen_loss = adv_loss + LAMBDA_PERC * perc_loss  # Weighted sum\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        loop.set_postfix({\n",
    "            \"D_loss\": f\"{disc_loss.item():.4f}\",\n",
    "            \"G_loss\": f\"{gen_loss.item():.4f}\",\n",
    "            \"perc_loss\": f\"{perc_loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    # Generate Images for Visualization\n",
    "    with torch.no_grad():\n",
    "        fake_images = gen(fixed_noise).detach().cpu()\n",
    "        img_grid = make_grid(fake_images, nrow=8, normalize=True)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6bdb95-6a02-4be8-a289-234ecc1c0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random noise vector\n",
    "random_noise = torch.randn(1, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "# Generate a random image\n",
    "with torch.no_grad():\n",
    "    random_image = gen(random_noise).detach().cpu()\n",
    "\n",
    "# Convert the tensor to a grid and display the image\n",
    "img_grid = make_grid(random_image, nrow=1, normalize=True)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27198c-255e-4cdf-8f75-272f90693a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_ = 4\n",
    "n = 100\n",
    "save_dir = f\"outputs/gan_iter_{iter_}/images/class\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "gen.eval()  # Set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for i in range(n):\n",
    "        noise = torch.randn(1, Z_DIM, 1, 1).to(device)  # Generate random noise\n",
    "        fake_image = gen(noise)  # Generate image\n",
    "        save_image(fake_image, os.path.join(save_dir, f\"generated_{i+1}.png\"), normalize=True)\n",
    "\n",
    "fid_custom.extract_and_save_features(save_dir, f\"outputs/gan_iter_{iter_}/features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
